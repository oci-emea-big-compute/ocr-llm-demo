# ocr-llm-demo
How to quickly setup a demo to demonstrate OCR capabilities of multimodal llm
New generation open multimodal llm are a very good fit for complex OCR workloads.
Many of the funcionalities that would require fine tuning with traditional OCR models can now be achieved with prompt engineering. 
The multilingual support, the hability to recognize handwriting are some of the features that can be used to improve OCR workloads.

## Prerequisites of the demo
The demo was run on Ubuntu 24.04. But it should be possible to run it on other Ubuntu versions.
You need to install
- Cuda toolkit/Nvidia Driver
- sudo apt-get install python-poppler

  
